{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_class.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg4noGOOVO4u",
        "colab_type": "text"
      },
      "source": [
        "# Introduction <a name=\"introduction\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLSHj3oCVUwz",
        "colab_type": "text"
      },
      "source": [
        "Deep convolutional neural network models may take days or even weeks to train on very large datasets.\n",
        "\n",
        "A way to simplify this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet and MNIST image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems. This is called **Transfer Learning**.\n",
        "\n",
        "In this project, we intend to use transfer learning when developing convolutional neural networks for an image classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XAFrqU3So9t",
        "colab_type": "text"
      },
      "source": [
        "# Objectives <a name=\"objectives\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VjLd8V7TQ6_",
        "colab_type": "text"
      },
      "source": [
        "* Perming some exploration on dataset\n",
        "* Selecting a pre-trained model on a publicly known dataset\n",
        "* Customizing the model for our specific problem\n",
        "* Freeze the parts of the model that we do not want to change\n",
        "* Train the model to do well with our dataset\n",
        "* Evaluate performance of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlSHdkkRVmFv",
        "colab_type": "text"
      },
      "source": [
        "# Selecting a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTMTQRPfB9Lp",
        "colab_type": "text"
      },
      "source": [
        "Since we are going to peform image classification, we will do well to use a dataset that is trained on the most popular dataset, ImageNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5YqEI7BYJ6e",
        "colab_type": "text"
      },
      "source": [
        "## ImageNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-xZKgbVYW-0",
        "colab_type": "text"
      },
      "source": [
        "ImageNet is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a \"synonym set\" or \"synset\". There are more than 100,000 synsets in WordNet, majority of them are nouns (80,000+). ImageNet, aims to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGegYPfoZ7SG",
        "colab_type": "text"
      },
      "source": [
        "![ImageNet Images](https://raw.githubusercontent.com/ml-heroes/ml-dataset/master/image-net.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Crlt_vd8LO",
        "colab_type": "text"
      },
      "source": [
        "## Monkey Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui_mRP6HgNpM",
        "colab_type": "text"
      },
      "source": [
        "The dataset consists of two files, training and validation. Each folder contains 10 subforders labeled as n0~n9, each corresponding a species form Wikipedia's monkey cladogram. Images are 400x300 px or larger and JPEG format (almost 1400 images). Images were downloaded with help of the googliser open source code.\n",
        "\n",
        "\n",
        "| Label   | Latin Name     | Common Name   | Train Images   | Validation Images   |\n",
        "|--------|--------------  |---------------|----------------|---------------------|\n",
        "| n0     | alouatta_palliata | mantled_howler | 131 | 26 |\n",
        "| n1     | erythrocebus_patas | patas_monkey | 139 | 28 |\n",
        "| n2     | cacajao_calvus | bald_uakari | 137 | 27 |\n",
        "| n3     | macaca_fuscata | japanese_macaque | 152 | 30 |\n",
        "| n4     | cebuella_pygmea | pygmy_marmoset |  131 | 26 |\n",
        "| n5     | cebus_capucinus | white_headed_capuchin| 141 | 28 |\n",
        "| n6     | mico_argentatus| silvery_marmoset| 132| 26 |\n",
        "| n7     | saimiri_sciureus | common_squirrel_monkey | 142 | 28 |\n",
        "| n8     | aotus_nigriceps | black_headed_night_monkey | 133 | 27 |\n",
        "| n9     | trachypithecus_johnii | nilgiri_langur | 132 | 26 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ndt5hWVfjQ",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SucHTj9Aj03i",
        "colab_type": "text"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND_39rS4j3LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format=\"svg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00qMg1DgkJgJ",
        "colab_type": "text"
      },
      "source": [
        "## Make our results reproducible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtLJ0-Xnjz2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "seed=1234\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8cWUvukapn",
        "colab_type": "text"
      },
      "source": [
        "##  Load dataset and process it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKOBKL4ykcXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As usual, define some paths first to make life simpler\n",
        "PATH = '/content/drive/My Drive/ml-dataset/monkey/'\n",
        "training_data = Path(PATH + 'training/') \n",
        "validation_data = Path(PATH + 'validation/') \n",
        "labels_path = Path(PATH + 'monkey_labels.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0hO7gZTnnjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "We will read the monkey_labels.txt file to extract the information about the labels. We can store this information in a list which then can be converted into a pandas dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDL3uIJqnrZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_info = []\n",
        "\n",
        "# Read the file\n",
        "lines = labels_path.read_text().strip().splitlines()[1:]\n",
        "for line in lines:\n",
        "    line = line.split(',')\n",
        "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
        "    line[3], line[4] = int(line[3]), int(line[4])\n",
        "    line = tuple(line)\n",
        "    labels_info.append(line)\n",
        "    \n",
        "# Convert the data into a pandas dataframe\n",
        "labels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n",
        "                                                 'Train Images', 'Validation Images'], index=None)\n",
        "# Sneak peek \n",
        "labels_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npdHfsGZnwbR",
        "colab_type": "text"
      },
      "source": [
        "The labels are n0, n1, n2, .... We will create a mapping of these labels where each class will be represented by an integer starting from 0 to number of classes. We will also create a mapping for the names corresponding to a class. We will be using Common Name for the last part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElYXVhIonzcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary to map the labels to integers\n",
        "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
        "cat = pd.Categorical(labels_info['Label'])\n",
        "labels_info['Label'] = cat.rename_categories(labels_dict)\n",
        "df = labels_info.drop(columns=['Train Images', 'Validation Images'])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_etDxi0n5Ap",
        "colab_type": "text"
      },
      "source": [
        "This is a very small dataset. You can load the data into numpy arrays which then can be directly used for training. But this isn't always the scenario. Most of the time you won't be able to load the entire dataset in the memory. This is why I always store information about the dataset in dataframes and then use a generator to load the data on the fly. We will be doing the same thing here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzRzncgSojS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dataframe for the training dataset\n",
        "train_df = []\n",
        "for folder in os.listdir(training_data):\n",
        "    # Define the path to the images\n",
        "    imgs_path = training_data / folder\n",
        "    \n",
        "    # Get the list of all the images stored in that directory\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    \n",
        "    # Store each image path and corresponding label \n",
        "    for img_name in imgs:\n",
        "        train_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# Creating dataframe for validation data in a similar fashion\n",
        "valid_df = []\n",
        "for folder in os.listdir(validation_data):\n",
        "    imgs_path = validation_data / folder\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    for img_name in imgs:\n",
        "        valid_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "        \n",
        "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# How many samples do we have in our training and validation data?\n",
        "print(\"Number of traininng samples: \", len(train_df))\n",
        "print(\"Number of validation samples: \", len(valid_df))\n",
        "\n",
        "# sneak peek of the training and validation dataframes\n",
        "print(\"\\n\",train_df.head(), \"\\n\")\n",
        "print(\"=================================================================\\n\")\n",
        "print(\"\\n\", valid_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW5YGsA57HvY",
        "colab_type": "text"
      },
      "source": [
        "## Viewing some monkeys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcamiSWA0TEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plots(ims, figsize=(12,6), rows=3, titles=None):\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, len(ims)//rows+1, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUBKcJnF0YqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = []\n",
        "labels = []\n",
        "\n",
        "for i in range(10):\n",
        "    file = os.listdir(f'{PATH}training/n%d'%i)\n",
        "    img = plt.imread(f'{PATH}training/n%d/{file[0]}'%i)\n",
        "    imgs.append(img)\n",
        "    name = df.loc[df['Label'] == i, 'Common Name'].item()\n",
        "    label = \"Class %d: %s\" % (i, name)\n",
        "    labels.append(label)\n",
        "\n",
        "plots(imgs, titles=labels, rows=4, figsize=(16,15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S43vyFyxx_sp",
        "colab_type": "text"
      },
      "source": [
        "## Checking missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Uz6IaHyYfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of records: \", len(train_df))\n",
        "print(\"Shape: \", train_df.shape)\n",
        "# Checks if there are any missing values\n",
        "print(\"\\nMissing data?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZpG5quVzI-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Train: \")\n",
        "train_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut4XbtEYzLN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Test: \")\n",
        "valid_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZhzokZQygZe",
        "colab_type": "text"
      },
      "source": [
        "We have absolutely no missing data in our dataset. All images have an associated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxuX0b_epedI",
        "colab_type": "text"
      },
      "source": [
        "## Data Distibution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H__eq5tzzWLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(x=\"label\", data=train_df);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ_echjEqirC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlim(0, 9)\n",
        "sns.distplot(train_df['label']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcyMg-R8zd3_",
        "colab_type": "text"
      },
      "source": [
        "We see a highly balanced dataset for our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iwfudCXzkyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(x=\"label\", data=valid_df);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2MFQo6mqtnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlim(0, 9)\n",
        "sns.distplot(valid_df['label']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvjlnzSqzpFU",
        "colab_type": "text"
      },
      "source": [
        "And our testing data is as well balanced across all labels.\n",
        "\n",
        "One other thing to notice is the similarity in the distribution of data for the training set and validation set. It will be safe to assume, this data was collected together but separated using a function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cryUZwtpaDX",
        "colab_type": "text"
      },
      "source": [
        "## Image Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR2KigVw_Ky5",
        "colab_type": "text"
      },
      "source": [
        "Look at image dimensions, confirm it's 3 band (RGB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhqcYkxV_IEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first = plt.imread(train_df.iloc[0].image)\n",
        "print(np.shape(first))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQ_DDvA_Yq9",
        "colab_type": "text"
      },
      "source": [
        "Image dimenion is 500x412x3. This shows a regular image with rgb coloring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fAdm3aYrlTE",
        "colab_type": "text"
      },
      "source": [
        "Confirm images are byte scaled (0-255)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNVFtcvIrl7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.min(first), np.max(first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH7hI_xep8wT",
        "colab_type": "text"
      },
      "source": [
        "## Check size distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-4COsz6qGYR",
        "colab_type": "text"
      },
      "source": [
        "Let's select group images ny their size and check for the distribution of image sizes. However downloading all images for this will take forever. Instead let's sample random 5 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp-5MHiWuBUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_dims(image):\n",
        "  im = plt.imread(image)\n",
        "  return np.shape(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftV7gDB-0fS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_data(df, label, size=10):\n",
        "  samples = df.loc[df['label'] == label].sample(size)\n",
        "  return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJSwHrAsufD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = cm.rainbow(np.linspace(0, 1, 10))\n",
        "\n",
        "for i in range(0, 10):\n",
        "  samples = sample_data(train_df, i)\n",
        "  images = samples['image']\n",
        "  dims = images.apply(get_image_dims)\n",
        "  width_height = dims.apply(lambda x: (x[0], x[1]))\n",
        "  plt.scatter(*zip(*width_height), color=colors[i], label=str(i))\n",
        "\n",
        "plt.title(\"Image sizes\")\n",
        "plt.xlabel('Width')\n",
        "plt.ylabel('Height')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTe6OZ8byJb8",
        "colab_type": "text"
      },
      "source": [
        "We can notice that from our sampling, many images are have size 500x500. With some few been very large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7PBmkPo35ZS",
        "colab_type": "text"
      },
      "source": [
        "There is no need to show the x-axis since there all the same value for x axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE-JF2JGyUGs",
        "colab_type": "text"
      },
      "source": [
        "This also confirms that the images are of different sizes and may need some pooling for size reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvJnf-k-ydUk",
        "colab_type": "text"
      },
      "source": [
        "We can also infer that all the images sampled have a third dimension with rgb format. This means we may need to perform some standardization to the colors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mfJVbW8yqvq",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTDxU-NXnWj",
        "colab_type": "text"
      },
      "source": [
        "There are perhaps a dozen or more top-performing models for image recognition that can be downloaded and used as the basis for image recognition and related computer vision tasks.\n",
        "\n",
        "Perhaps three of the more popular models are as follows:\n",
        "\n",
        "* VGG (e.g. VGG16 or VGG19).\n",
        "*GoogLeNet (e.g. InceptionV3).\n",
        "* Residual Network (e.g. ResNet50).\n",
        "\n",
        "These models are both widely used for transfer learning both because of their performance, but also because they were examples that introduced specific architectural innovations, namely consistent and repeating structures (VGG), inception modules (GoogLeNet), and residual modules (ResNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tMCd4aK-Y-y",
        "colab_type": "text"
      },
      "source": [
        "We will use a pre trained Deep Convolutional Neural Network \"Xception\" to transfer learn on our own Data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBu5zgWB60FA",
        "colab_type": "text"
      },
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXchmIt62X6",
        "colab_type": "text"
      },
      "source": [
        "Xception by Google, stands for Extreme version of Inception. With a modified depthwise separable convolution, it is even better than Inception-v3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf5aNVW871Pl",
        "colab_type": "text"
      },
      "source": [
        "## Original Architecture (Inception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS9YsNGv74MD",
        "colab_type": "text"
      },
      "source": [
        "![Original Architecture](https://raw.githubusercontent.com/ml-heroes/ml-dataset/master/original_xception.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nZm_yj9-O21",
        "colab_type": "text"
      },
      "source": [
        "> *Original Depthwise Separable Convolution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fURam6D745N",
        "colab_type": "text"
      },
      "source": [
        "The original depthwise separable convolution is the depthwise convolution followed by a pointwise convolution.\n",
        "* Depthwise convolution is the channel-wise n×n spatial convolution. Suppose in the figure above, we have 5 channels, then we will have 5 n×n spatial convolution.\n",
        "* Pointwise convolution actually is the 1×1 convolution to change the dimension.\n",
        "\n",
        "Compared with conventional convolution, we do not need to perform convolution across all channels. That means the number of connections are fewer and the model is lighter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYoJsyJK9PaB",
        "colab_type": "text"
      },
      "source": [
        "## Modified Architecture (Xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWpPqvZo9aBj",
        "colab_type": "text"
      },
      "source": [
        "![Original Architecture](https://raw.githubusercontent.com/ml-heroes/ml-dataset/master/modified_xception.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRTpVHUw98wL",
        "colab_type": "text"
      },
      "source": [
        "> *The Modified Depthwise Separable Convolution used as an Inception Module in Xception, so called “extreme” version of Inception module (n=3 here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2VKhF4U9YKa",
        "colab_type": "text"
      },
      "source": [
        "The modified depthwise separable convolution is the pointwise convolution followed by a depthwise convolution. This modification is motivated by the inception module in Inception-v3 that 1×1 convolution is done first before any n×n spatial convolutions. Thus, it is a bit different from the original one. (n=3 here since 3×3 spatial convolutions are used in Inception-v3.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYesCPTg_JPm",
        "colab_type": "text"
      },
      "source": [
        "## Comparison of ImageNet: Xception Model with other Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AeoyTur_Tuf",
        "colab_type": "text"
      },
      "source": [
        "![Original Architecture](https://raw.githubusercontent.com/ml-heroes/ml-dataset/master/compare.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr51iKYp_dok",
        "colab_type": "text"
      },
      "source": [
        "> *ImageNet: Xception has the Highest Accuracy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1aIUuv5-foA",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4T3M3yxfhbp",
        "colab_type": "text"
      },
      "source": [
        "> Describe model structure here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFxI1dMPf3IV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0j2o_RX_6lw",
        "colab_type": "text"
      },
      "source": [
        "> Describe how model is trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTzShxpf5dT",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzEuTEs_9gs",
        "colab_type": "text"
      },
      "source": [
        "> Show graphs and results here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASoTLvHQf7qm",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChNJQFTuAAiv",
        "colab_type": "text"
      },
      "source": [
        "> Final Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoZ41x-Vxyo",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfy6emZoAD1U",
        "colab_type": "text"
      },
      "source": [
        "* https://medium.com/analytics-vidhya/image-recognition-using-pre-trained-xception-model-in-5-steps-96ac858f4206\n",
        "* https://www.kaggle.com/aakashnain/what-does-a-cnn-see\n",
        "* https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf"
      ]
    }
  ]
}